{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4833564a",
   "metadata": {},
   "source": [
    "# Fine Tuning do Modelo GPT-4.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545150e0",
   "metadata": {},
   "source": [
    "1. Crie uma conta na Plataforma de desenvolvimento da OpenAI.\n",
    "2. Insira pelo menos U$5,00 de crÃ©dito.\n",
    "3. Crie uma chave API da OpenAI\n",
    "4. Crie um script em Python (com auxÃ­lio de LLMs) para checar a acurÃ¡cia do modelo gpt-4.1-nano frente ao problema de classificaÃ§Ã£o de requisitos de sistemas nas categorias \"funcional\" e \"nÃ£o-funcional\". Utilize o arquivo \"dataset.jsonl\" para isso. O script deverÃ¡ exibir ao final a quantidade de classificaÃ§Ãµes corretas e a porcentagem do total. Se vocÃª nunca programou em Python, peÃ§a auxÃ­lio de um LLM para instalar o Python e outras dependÃªncias necessÃ¡rias. \n",
    "5. Realize o Fine Tuning do modelo gpt-4.1-nano com arquivo \"dataset-train.jsonl\". Ao criar o job de treinamento, use como sufixo o e-mail que vocÃª utilizou para se cadastrar ao classroom (e.g. \"aluno@ga.ita.br\").\n",
    "6. Crie um script em Python (com auxÃ­lio de LLMs) para transformar o conteÃºdo do arquivo \"dataset-test2.xlsx\" numa base de dados em JSONL.\n",
    "7. Una as instÃ¢ncias constantes no arquivo \"dataset-test.jsonl\" com as instÃ¢ncias oriundas do arquivo \"dataset-test2.xlsx\" (que vocÃª passou para JSONL no passo 6) para criar uma base de dados de teste com um nÃºmero maior de instÃ¢ncias. \n",
    "6. Crie outro script em Python (com auxÃ­lio de LLMs) para checar a acurÃ¡cia do modelo gpt-4.1-nano \"tunado\", utilizando o dataset de teste que vocÃª criou no passo 7. O script deverÃ¡ exibir ao final a quantidade de classificaÃ§Ãµes corretas e a porcentagem do total. \n",
    "7. Entregue: \n",
    "\n",
    "     a) Todos os scripts. Lembre-se de documentar bem o seu cÃ³digo!\n",
    "     \n",
    "     b) O identificador Ãºnico do seu modelo \"tunado\", nomeado com um sufixo com seu e-mail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cd8450",
   "metadata": {},
   "source": [
    "### ImportaÃ§Ã£o de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f01bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97261f4b",
   "metadata": {},
   "source": [
    "### TransformaÃ§Ã£o do conteÃºdo do arquivo \"dataset-test2.xlsx\" numa base de dados em JSONL. (Item 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f368597e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Arquivo JSONL criado em: data/jsonl/dataset-test2.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Caminhos\n",
    "input_file = \"data/xlsx/dataset-test2.xlsx\"\n",
    "output_file = \"data/jsonl/dataset-test2.jsonl\"\n",
    "\n",
    "# Carrega Excel\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are a Software Engineer and need to categorize requirements into \"\n",
    "    \"'functional' or 'non-functional'. Your answer must be 'functional' or 'non-functional' only.\"\n",
    ")\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for _, row in df.iterrows():\n",
    "        requirement = str(row[\"requirement\"]).strip()\n",
    "        \n",
    "        # Interpreta a coluna NF\n",
    "        nf_value = row[\"NF\"]\n",
    "        if str(nf_value).strip().lower() in [\"1\", \"non-functional\", \"nf\"]:\n",
    "            label = \"non-functional\"\n",
    "        else:\n",
    "            label = \"functional\"\n",
    "        \n",
    "        example = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": requirement},\n",
    "                {\"role\": \"assistant\", \"content\": label}\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        f.write(json.dumps(example, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"âœ… Arquivo JSONL criado em: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb3819c",
   "metadata": {},
   "source": [
    "### CriaÃ§Ã£o do arquivo \"dataset-test-final.jsonl\", oriundo da uniÃ£o da instÃ¢ncias do arquivo \"dataset-test.jsonl\" com as instÃ¢ncias do arquivo \"dataset-test2.xlsx\". (Item 7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d78e6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Arquivo combinado salvo em: data/jsonl/dataset-test-final.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Arquivos de entrada\n",
    "file1 = \"data/jsonl/dataset-test2.jsonl\"\n",
    "file2 = \"data/jsonl/dataset-test.jsonl\"\n",
    "\n",
    "# Arquivo de saÃ­da\n",
    "output_file = \"data/jsonl/dataset-test-final.jsonl\"\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    # Copia as linhas do primeiro arquivo\n",
    "    with open(file1, \"r\", encoding=\"utf-8\") as infile1:\n",
    "        for line in infile1:\n",
    "            outfile.write(line)\n",
    "    # Copia as linhas do segundo arquivo\n",
    "    with open(file2, \"r\", encoding=\"utf-8\") as infile2:\n",
    "        for line in infile2:\n",
    "            outfile.write(line)\n",
    "\n",
    "print(f\"âœ… Arquivo combinado salvo em: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523f6861",
   "metadata": {},
   "source": [
    "### Checando acurÃ¡cia dos modelos. (Itens 4 e 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f211f7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Œ Modelo: gpt-4.1-nano-2025-04-14\n",
      "   âœ… Total exemplos: 71\n",
      "   ðŸŽ¯ Acertos: 40\n",
      "   ðŸ“Š AcurÃ¡cia: 56.34%\n",
      "\n",
      "ðŸ“Œ Modelo: ft:gpt-4.1-nano-2025-04-14:personal:te-251-carlos-figueiredo:CAUgUYUQ\n",
      "   âœ… Total exemplos: 71\n",
      "   ðŸŽ¯ Acertos: 58\n",
      "   ðŸ“Š AcurÃ¡cia: 81.69%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Carregar variÃ¡veis de ambiente\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Dataset\n",
    "dataset_file = \"data/jsonl/dataset-test-final.jsonl\"\n",
    "\n",
    "# Modelos a comparar\n",
    "models = {\n",
    "    \"base\": \"gpt-4.1-nano-2025-04-14\",\n",
    "    \"fine_tuned\": \"ft:gpt-4.1-nano-2025-04-14:personal:te-251-carlos-figueiredo:CAUgUYUQ\"\n",
    "}\n",
    "\n",
    "# Contadores\n",
    "results = {name: {\"total\": 0, \"correct\": 0} for name in models}\n",
    "\n",
    "with open(dataset_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        example = json.loads(line)\n",
    "        messages = example[\"messages\"]\n",
    "\n",
    "        # expected = Ãºltima resposta (assistant)\n",
    "        expected = messages[-1][\"content\"].strip().lower()\n",
    "        eval_messages = messages[:-1]  # sem o rÃ³tulo\n",
    "\n",
    "        for name, model in models.items():\n",
    "            results[name][\"total\"] += 1\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=eval_messages,\n",
    "                temperature=0\n",
    "            )\n",
    "            predicted = response.choices[0].message.content.strip().lower()\n",
    "\n",
    "            if predicted == expected:\n",
    "                results[name][\"correct\"] += 1\n",
    "\n",
    "# Exibe resultados\n",
    "for name, stats in results.items():\n",
    "    total = stats[\"total\"]\n",
    "    correct = stats[\"correct\"]\n",
    "    accuracy = (correct / total * 100) if total > 0 else 0\n",
    "    print(f\"ðŸ“Œ Modelo: {models[name]}\")\n",
    "    print(f\"   âœ… Total exemplos: {total}\")\n",
    "    print(f\"   ðŸŽ¯ Acertos: {correct}\")\n",
    "    print(f\"   ðŸ“Š AcurÃ¡cia: {accuracy:.2f}%\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
