{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4833564a",
   "metadata": {},
   "source": [
    "# Fine Tuning do Modelo GPT-4.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545150e0",
   "metadata": {},
   "source": [
    "1. Crie uma conta na Plataforma de desenvolvimento da OpenAI.\n",
    "2. Insira pelo menos U$5,00 de crédito.\n",
    "3. Crie uma chave API da OpenAI\n",
    "4. Crie um script em Python (com auxílio de LLMs) para checar a acurácia do modelo gpt-4.1-nano frente ao problema de classificação de requisitos de sistemas nas categorias \"funcional\" e \"não-funcional\". Utilize o arquivo \"dataset.jsonl\" para isso. O script deverá exibir ao final a quantidade de classificações corretas e a porcentagem do total. Se você nunca programou em Python, peça auxílio de um LLM para instalar o Python e outras dependências necessárias. \n",
    "5. Realize o Fine Tuning do modelo gpt-4.1-nano com arquivo \"dataset-train.jsonl\". Ao criar o job de treinamento, use como sufixo o e-mail que você utilizou para se cadastrar ao classroom (e.g. \"aluno@ga.ita.br\").\n",
    "6. Crie um script em Python (com auxílio de LLMs) para transformar o conteúdo do arquivo \"dataset-test2.xlsx\" numa base de dados em JSONL.\n",
    "7. Una as instâncias constantes no arquivo \"dataset-test.jsonl\" com as instâncias oriundas do arquivo \"dataset-test2.xlsx\" (que você passou para JSONL no passo 6) para criar uma base de dados de teste com um número maior de instâncias. \n",
    "6. Crie outro script em Python (com auxílio de LLMs) para checar a acurácia do modelo gpt-4.1-nano \"tunado\", utilizando o dataset de teste que você criou no passo 7. O script deverá exibir ao final a quantidade de classificações corretas e a porcentagem do total. \n",
    "7. Entregue: \n",
    "\n",
    "     a) Todos os scripts. Lembre-se de documentar bem o seu código!\n",
    "     \n",
    "     b) O identificador único do seu modelo \"tunado\", nomeado com um sufixo com seu e-mail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cd8450",
   "metadata": {},
   "source": [
    "### Importação de Bibliotecas necessárias ao projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f01bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pandas - biblioteca para manipulação e análise de dados estruturados\n",
    "import pandas as pd\n",
    "\n",
    "# JSON - biblioteca nativa do Python para trabalhar com dados em formato JSON\n",
    "import json\n",
    "\n",
    "# OS - biblioteca nativa para interação com o sistema operacional (caminhos, variáveis de ambiente, etc.)\n",
    "import os\n",
    "\n",
    "# OpenAI - cliente oficial da API da OpenAI para integração com modelos de linguagem\n",
    "from openai import OpenAI\n",
    "\n",
    "# python-dotenv - biblioteca para carregar variáveis de ambiente de arquivos .env\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97261f4b",
   "metadata": {},
   "source": [
    "### Transformação do conteúdo do arquivo \"dataset-test2.xlsx\" numa base de dados em JSONL. (Item 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f368597e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Arquivo JSONL criado em: data/jsonl/dataset-test2.jsonl\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURAÇÃO DE CAMINHOS E CARREGAMENTO DE DADOS\n",
    "# =============================================================================\n",
    "\n",
    "# Define os caminhos de entrada (Excel) e saída (JSONL)\n",
    "input_file = \"data/xlsx/dataset-test2.xlsx\"   # Arquivo Excel com os dados originais\n",
    "output_file = \"data/jsonl/dataset-test2.jsonl\"  # Arquivo JSONL de saída para treinamento\n",
    "\n",
    "# Carrega o dataset do arquivo Excel em um DataFrame do pandas\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "# =============================================================================\n",
    "# DEFINIÇÃO DO PROMPT DO SISTEMA\n",
    "# =============================================================================\n",
    "\n",
    "# Prompt que define o comportamento do modelo: classificar requirements como\n",
    "# funcionais ou não-funcionais, retornando apenas uma das duas categorias\n",
    "system_prompt = (\n",
    "    \"You are a Software Engineer and need to categorize requirements into \"\n",
    "    \"'functional' or 'non-functional'. Your answer must be 'functional' or 'non-functional' only.\"\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# CONVERSÃO PARA FORMATO JSONL (OPENAI FINE-TUNING)\n",
    "# =============================================================================\n",
    "\n",
    "# Abre o arquivo de saída em modo escrita com encoding UTF-8\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    # Itera sobre cada linha do DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        # Extrai e limpa o texto do requirement\n",
    "        requirement = str(row[\"requirement\"]).strip()\n",
    "       \n",
    "        # Interpreta a coluna \"NF\" para determinar o rótulo correto\n",
    "        nf_value = row[\"NF\"]\n",
    "        if str(nf_value).strip().lower() in [\"1\", \"non-functional\", \"nf\"]:\n",
    "            label = \"non-functional\"  # Requirement não-funcional\n",
    "        else:\n",
    "            label = \"functional\"      # Requirement funcional (padrão)\n",
    "       \n",
    "        # Cria o exemplo no formato esperado pela API OpenAI para fine-tuning\n",
    "        # Estrutura: system prompt + entrada do usuário + resposta esperada\n",
    "        example = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},      # Instruções do sistema\n",
    "                {\"role\": \"user\", \"content\": requirement},          # Requirement a ser classificado\n",
    "                {\"role\": \"assistant\", \"content\": label}            # Classificação esperada\n",
    "            ]\n",
    "        }\n",
    "       \n",
    "        # Escreve o exemplo como uma linha JSON no arquivo JSONL\n",
    "        f.write(json.dumps(example, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# Confirma a criação bem-sucedida do arquivo\n",
    "print(f\"✅ Arquivo JSONL criado em: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb3819c",
   "metadata": {},
   "source": [
    "### Criação do arquivo \"dataset-test-final.jsonl\", oriundo da união da instâncias do arquivo \"dataset-test.jsonl\" com as instâncias do arquivo \"dataset-test2.xlsx\". (Item 7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d78e6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Arquivo combinado salvo em: data/jsonl/dataset-test-final.jsonl\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONCATENAÇÃO DE DATASETS JSONL\n",
    "# =============================================================================\n",
    "\n",
    "# Define os arquivos de entrada que serão combinados\n",
    "file1 = \"data/jsonl/dataset-test2.jsonl\"  # Primeiro dataset JSONL\n",
    "file2 = \"data/jsonl/dataset-test.jsonl\"   # Segundo dataset JSONL\n",
    "\n",
    "# Define o arquivo de saída que conterá os dados combinados\n",
    "output_file = \"data/jsonl/dataset-test-final.jsonl\"\n",
    "\n",
    "# =============================================================================\n",
    "# PROCESSO DE CONCATENAÇÃO\n",
    "# =============================================================================\n",
    "\n",
    "# Abre o arquivo de saída em modo escrita\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    \n",
    "    # Copia todas as linhas do primeiro arquivo\n",
    "    with open(file1, \"r\", encoding=\"utf-8\") as infile1:\n",
    "        for line in infile1:\n",
    "            outfile.write(line)  # Preserva a formatação JSONL original\n",
    "    \n",
    "    # Copia todas as linhas do segundo arquivo\n",
    "    with open(file2, \"r\", encoding=\"utf-8\") as infile2:\n",
    "        for line in infile2:\n",
    "            outfile.write(line)  # Adiciona ao final do primeiro dataset\n",
    "\n",
    "# Confirma a operação bem-sucedida\n",
    "print(f\"✅ Arquivo combinado salvo em: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523f6861",
   "metadata": {},
   "source": [
    "### Checando acurácia dos modelos. (Itens 4 e 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f211f7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Modelo: gpt-4.1-nano-2025-04-14\n",
      "   ✅ Total exemplos: 71\n",
      "   🎯 Acertos: 40\n",
      "   📊 Acurácia: 56.34%\n",
      "\n",
      "📌 Modelo: ft:gpt-4.1-nano-2025-04-14:personal:te-251-carlos-figueiredo:CAUgUYUQ\n",
      "   ✅ Total exemplos: 71\n",
      "   🎯 Acertos: 58\n",
      "   📊 Acurácia: 81.69%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURAÇÃO E INICIALIZAÇÃO\n",
    "# =============================================================================\n",
    "\n",
    "# Carrega as variáveis de ambiente do arquivo .env (incluindo chave da API)\n",
    "load_dotenv()\n",
    "\n",
    "# Inicializa o cliente da OpenAI com a chave de API do ambiente\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Define o arquivo de dataset que será usado para avaliação\n",
    "dataset_file = \"data/jsonl/dataset-test-final.jsonl\"\n",
    "\n",
    "# =============================================================================\n",
    "# DEFINIÇÃO DOS MODELOS A COMPARAR\n",
    "# =============================================================================\n",
    "\n",
    "# Dicionário com os modelos que serão avaliados:\n",
    "# - base: modelo padrão da OpenAI sem fine-tuning\n",
    "# - fine_tuned: modelo personalizado treinado especificamente para esta tarefa\n",
    "models = {\n",
    "    \"base\": \"gpt-4.1-nano-2025-04-14\",  # Modelo base\n",
    "    \"fine_tuned\": \"ft:gpt-4.1-nano-2025-04-14:personal:te-251-carlos-figueiredo:CAUgUYUQ\"  # Modelo fine-tuned\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# INICIALIZAÇÃO DOS CONTADORES\n",
    "# =============================================================================\n",
    "\n",
    "# Cria estrutura para armazenar resultados de cada modelo\n",
    "# Para cada modelo: total de exemplos testados e número de acertos\n",
    "results = {name: {\"total\": 0, \"correct\": 0} for name in models}\n",
    "\n",
    "# =============================================================================\n",
    "# AVALIAÇÃO DOS MODELOS\n",
    "# =============================================================================\n",
    "\n",
    "# Processa cada exemplo do dataset de teste\n",
    "with open(dataset_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        # Carrega o exemplo JSON\n",
    "        example = json.loads(line)\n",
    "        messages = example[\"messages\"]\n",
    "        \n",
    "        # Extrai a resposta esperada (última mensagem do assistant)\n",
    "        expected = messages[-1][\"content\"].strip().lower()\n",
    "        \n",
    "        # Cria mensagens para avaliação (remove a resposta correta)\n",
    "        eval_messages = messages[:-1]  # System prompt + user input, sem o rótulo\n",
    "        \n",
    "        # Testa cada modelo com o mesmo exemplo\n",
    "        for name, model in models.items():\n",
    "            results[name][\"total\"] += 1  # Incrementa contador total\n",
    "            \n",
    "            # Faz a predição usando o modelo atual\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=eval_messages,\n",
    "                temperature=0  # Determinístico para avaliação consistente\n",
    "            )\n",
    "            \n",
    "            # Extrai e normaliza a resposta do modelo\n",
    "            predicted = response.choices[0].message.content.strip().lower()\n",
    "            \n",
    "            # Verifica se a predição está correta\n",
    "            if predicted == expected:\n",
    "                results[name][\"correct\"] += 1  # Incrementa contador de acertos\n",
    "\n",
    "# =============================================================================\n",
    "# EXIBIÇÃO DOS RESULTADOS\n",
    "# =============================================================================\n",
    "\n",
    "# Calcula e exibe métricas de desempenho para cada modelo\n",
    "for name, stats in results.items():\n",
    "    total = stats[\"total\"]\n",
    "    correct = stats[\"correct\"]\n",
    "    \n",
    "    # Calcula a acurácia (% de acertos)\n",
    "    accuracy = (correct / total * 100) if total > 0 else 0\n",
    "    \n",
    "    # Exibe resultados formatados\n",
    "    print(f\"📌 Modelo: {models[name]}\")\n",
    "    print(f\"   ✅ Total exemplos: {total}\")\n",
    "    print(f\"   🎯 Acertos: {correct}\")\n",
    "    print(f\"   📊 Acurácia: {accuracy:.2f}%\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
