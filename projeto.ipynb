{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4833564a",
   "metadata": {},
   "source": [
    "# Fine Tuning do Modelo GPT-4.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545150e0",
   "metadata": {},
   "source": [
    "1. Crie uma conta na Plataforma de desenvolvimento da OpenAI.\n",
    "2. Insira pelo menos U$5,00 de crﾃｩdito.\n",
    "3. Crie uma chave API da OpenAI\n",
    "4. Crie um script em Python (com auxﾃｭlio de LLMs) para checar a acurﾃ｡cia do modelo gpt-4.1-nano frente ao problema de classificaﾃｧﾃ｣o de requisitos de sistemas nas categorias \"funcional\" e \"nﾃ｣o-funcional\". Utilize o arquivo \"dataset.jsonl\" para isso. O script deverﾃ｡ exibir ao final a quantidade de classificaﾃｧﾃｵes corretas e a porcentagem do total. Se vocﾃｪ nunca programou em Python, peﾃｧa auxﾃｭlio de um LLM para instalar o Python e outras dependﾃｪncias necessﾃ｡rias. \n",
    "5. Realize o Fine Tuning do modelo gpt-4.1-nano com arquivo \"dataset-train.jsonl\". Ao criar o job de treinamento, use como sufixo o e-mail que vocﾃｪ utilizou para se cadastrar ao classroom (e.g. \"aluno@ga.ita.br\").\n",
    "6. Crie um script em Python (com auxﾃｭlio de LLMs) para transformar o conteﾃｺdo do arquivo \"dataset-test2.xlsx\" numa base de dados em JSONL.\n",
    "7. Una as instﾃ｢ncias constantes no arquivo \"dataset-test.jsonl\" com as instﾃ｢ncias oriundas do arquivo \"dataset-test2.xlsx\" (que vocﾃｪ passou para JSONL no passo 6) para criar uma base de dados de teste com um nﾃｺmero maior de instﾃ｢ncias. \n",
    "6. Crie outro script em Python (com auxﾃｭlio de LLMs) para checar a acurﾃ｡cia do modelo gpt-4.1-nano \"tunado\", utilizando o dataset de teste que vocﾃｪ criou no passo 7. O script deverﾃ｡ exibir ao final a quantidade de classificaﾃｧﾃｵes corretas e a porcentagem do total. \n",
    "7. Entregue: \n",
    "\n",
    "     a) Todos os scripts. Lembre-se de documentar bem o seu cﾃｳdigo!\n",
    "     \n",
    "     b) O identificador ﾃｺnico do seu modelo \"tunado\", nomeado com um sufixo com seu e-mail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cd8450",
   "metadata": {},
   "source": [
    "### Importaﾃｧﾃ｣o de Bibliotecas necessﾃ｡rias ao projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f01bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pandas - biblioteca para manipulaﾃｧﾃ｣o e anﾃ｡lise de dados estruturados\n",
    "import pandas as pd\n",
    "\n",
    "# JSON - biblioteca nativa do Python para trabalhar com dados em formato JSON\n",
    "import json\n",
    "\n",
    "# OS - biblioteca nativa para interaﾃｧﾃ｣o com o sistema operacional (caminhos, variﾃ｡veis de ambiente, etc.)\n",
    "import os\n",
    "\n",
    "# OpenAI - cliente oficial da API da OpenAI para integraﾃｧﾃ｣o com modelos de linguagem\n",
    "from openai import OpenAI\n",
    "\n",
    "# python-dotenv - biblioteca para carregar variﾃ｡veis de ambiente de arquivos .env\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97261f4b",
   "metadata": {},
   "source": [
    "### Transformaﾃｧﾃ｣o do conteﾃｺdo do arquivo \"dataset-test2.xlsx\" numa base de dados em JSONL. (Item 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f368597e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "笨 Arquivo JSONL criado em: data/jsonl/dataset-test2.jsonl\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURAﾃﾃグ DE CAMINHOS E CARREGAMENTO DE DADOS\n",
    "# =============================================================================\n",
    "\n",
    "# Define os caminhos de entrada (Excel) e saﾃｭda (JSONL)\n",
    "input_file = \"data/xlsx/dataset-test2.xlsx\"   # Arquivo Excel com os dados originais\n",
    "output_file = \"data/jsonl/dataset-test2.jsonl\"  # Arquivo JSONL de saﾃｭda para treinamento\n",
    "\n",
    "# Carrega o dataset do arquivo Excel em um DataFrame do pandas\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "# =============================================================================\n",
    "# DEFINIﾃﾃグ DO PROMPT DO SISTEMA\n",
    "# =============================================================================\n",
    "\n",
    "# Prompt que define o comportamento do modelo: classificar requirements como\n",
    "# funcionais ou nﾃ｣o-funcionais, retornando apenas uma das duas categorias\n",
    "system_prompt = (\n",
    "    \"You are a Software Engineer and need to categorize requirements into \"\n",
    "    \"'functional' or 'non-functional'. Your answer must be 'functional' or 'non-functional' only.\"\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# CONVERSﾃグ PARA FORMATO JSONL (OPENAI FINE-TUNING)\n",
    "# =============================================================================\n",
    "\n",
    "# Abre o arquivo de saﾃｭda em modo escrita com encoding UTF-8\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    # Itera sobre cada linha do DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        # Extrai e limpa o texto do requirement\n",
    "        requirement = str(row[\"requirement\"]).strip()\n",
    "       \n",
    "        # Interpreta a coluna \"NF\" para determinar o rﾃｳtulo correto\n",
    "        nf_value = row[\"NF\"]\n",
    "        if str(nf_value).strip().lower() in [\"1\", \"non-functional\", \"nf\"]:\n",
    "            label = \"non-functional\"  # Requirement nﾃ｣o-funcional\n",
    "        else:\n",
    "            label = \"functional\"      # Requirement funcional (padrﾃ｣o)\n",
    "       \n",
    "        # Cria o exemplo no formato esperado pela API OpenAI para fine-tuning\n",
    "        # Estrutura: system prompt + entrada do usuﾃ｡rio + resposta esperada\n",
    "        example = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},      # Instruﾃｧﾃｵes do sistema\n",
    "                {\"role\": \"user\", \"content\": requirement},          # Requirement a ser classificado\n",
    "                {\"role\": \"assistant\", \"content\": label}            # Classificaﾃｧﾃ｣o esperada\n",
    "            ]\n",
    "        }\n",
    "       \n",
    "        # Escreve o exemplo como uma linha JSON no arquivo JSONL\n",
    "        f.write(json.dumps(example, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# Confirma a criaﾃｧﾃ｣o bem-sucedida do arquivo\n",
    "print(f\"笨 Arquivo JSONL criado em: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb3819c",
   "metadata": {},
   "source": [
    "### Criaﾃｧﾃ｣o do arquivo \"dataset-test-final.jsonl\", oriundo da uniﾃ｣o da instﾃ｢ncias do arquivo \"dataset-test.jsonl\" com as instﾃ｢ncias do arquivo \"dataset-test2.xlsx\". (Item 7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d78e6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "笨 Arquivo combinado salvo em: data/jsonl/dataset-test-final.jsonl\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONCATENAﾃﾃグ DE DATASETS JSONL\n",
    "# =============================================================================\n",
    "\n",
    "# Define os arquivos de entrada que serﾃ｣o combinados\n",
    "file1 = \"data/jsonl/dataset-test2.jsonl\"  # Primeiro dataset JSONL\n",
    "file2 = \"data/jsonl/dataset-test.jsonl\"   # Segundo dataset JSONL\n",
    "\n",
    "# Define o arquivo de saﾃｭda que conterﾃ｡ os dados combinados\n",
    "output_file = \"data/jsonl/dataset-test-final.jsonl\"\n",
    "\n",
    "# =============================================================================\n",
    "# PROCESSO DE CONCATENAﾃﾃグ\n",
    "# =============================================================================\n",
    "\n",
    "# Abre o arquivo de saﾃｭda em modo escrita\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    \n",
    "    # Copia todas as linhas do primeiro arquivo\n",
    "    with open(file1, \"r\", encoding=\"utf-8\") as infile1:\n",
    "        for line in infile1:\n",
    "            outfile.write(line)  # Preserva a formataﾃｧﾃ｣o JSONL original\n",
    "    \n",
    "    # Copia todas as linhas do segundo arquivo\n",
    "    with open(file2, \"r\", encoding=\"utf-8\") as infile2:\n",
    "        for line in infile2:\n",
    "            outfile.write(line)  # Adiciona ao final do primeiro dataset\n",
    "\n",
    "# Confirma a operaﾃｧﾃ｣o bem-sucedida\n",
    "print(f\"笨 Arquivo combinado salvo em: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523f6861",
   "metadata": {},
   "source": [
    "### Checando acurﾃ｡cia dos modelos. (Itens 4 e 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f211f7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "沒 Modelo: gpt-4.1-nano-2025-04-14\n",
      "   笨 Total exemplos: 71\n",
      "   沁ｯ Acertos: 40\n",
      "   沒 Acurﾃ｡cia: 56.34%\n",
      "\n",
      "沒 Modelo: ft:gpt-4.1-nano-2025-04-14:personal:te-251-carlos-figueiredo:CAUgUYUQ\n",
      "   笨 Total exemplos: 71\n",
      "   沁ｯ Acertos: 58\n",
      "   沒 Acurﾃ｡cia: 81.69%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURAﾃﾃグ E INICIALIZAﾃﾃグ\n",
    "# =============================================================================\n",
    "\n",
    "# Carrega as variﾃ｡veis de ambiente do arquivo .env (incluindo chave da API)\n",
    "load_dotenv()\n",
    "\n",
    "# Inicializa o cliente da OpenAI com a chave de API do ambiente\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Define o arquivo de dataset que serﾃ｡ usado para avaliaﾃｧﾃ｣o\n",
    "dataset_file = \"data/jsonl/dataset-test-final.jsonl\"\n",
    "\n",
    "# =============================================================================\n",
    "# DEFINIﾃﾃグ DOS MODELOS A COMPARAR\n",
    "# =============================================================================\n",
    "\n",
    "# Dicionﾃ｡rio com os modelos que serﾃ｣o avaliados:\n",
    "# - base: modelo padrﾃ｣o da OpenAI sem fine-tuning\n",
    "# - fine_tuned: modelo personalizado treinado especificamente para esta tarefa\n",
    "models = {\n",
    "    \"base\": \"gpt-4.1-nano-2025-04-14\",  # Modelo base\n",
    "    \"fine_tuned\": \"ft:gpt-4.1-nano-2025-04-14:personal:te-251-carlos-figueiredo:CAUgUYUQ\"  # Modelo fine-tuned\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# INICIALIZAﾃﾃグ DOS CONTADORES\n",
    "# =============================================================================\n",
    "\n",
    "# Cria estrutura para armazenar resultados de cada modelo\n",
    "# Para cada modelo: total de exemplos testados e nﾃｺmero de acertos\n",
    "results = {name: {\"total\": 0, \"correct\": 0} for name in models}\n",
    "\n",
    "# =============================================================================\n",
    "# AVALIAﾃﾃグ DOS MODELOS\n",
    "# =============================================================================\n",
    "\n",
    "# Processa cada exemplo do dataset de teste\n",
    "with open(dataset_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        # Carrega o exemplo JSON\n",
    "        example = json.loads(line)\n",
    "        messages = example[\"messages\"]\n",
    "        \n",
    "        # Extrai a resposta esperada (ﾃｺltima mensagem do assistant)\n",
    "        expected = messages[-1][\"content\"].strip().lower()\n",
    "        \n",
    "        # Cria mensagens para avaliaﾃｧﾃ｣o (remove a resposta correta)\n",
    "        eval_messages = messages[:-1]  # System prompt + user input, sem o rﾃｳtulo\n",
    "        \n",
    "        # Testa cada modelo com o mesmo exemplo\n",
    "        for name, model in models.items():\n",
    "            results[name][\"total\"] += 1  # Incrementa contador total\n",
    "            \n",
    "            # Faz a prediﾃｧﾃ｣o usando o modelo atual\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=eval_messages,\n",
    "                temperature=0  # Determinﾃｭstico para avaliaﾃｧﾃ｣o consistente\n",
    "            )\n",
    "            \n",
    "            # Extrai e normaliza a resposta do modelo\n",
    "            predicted = response.choices[0].message.content.strip().lower()\n",
    "            \n",
    "            # Verifica se a prediﾃｧﾃ｣o estﾃ｡ correta\n",
    "            if predicted == expected:\n",
    "                results[name][\"correct\"] += 1  # Incrementa contador de acertos\n",
    "\n",
    "# =============================================================================\n",
    "# EXIBIﾃﾃグ DOS RESULTADOS\n",
    "# =============================================================================\n",
    "\n",
    "# Calcula e exibe mﾃｩtricas de desempenho para cada modelo\n",
    "for name, stats in results.items():\n",
    "    total = stats[\"total\"]\n",
    "    correct = stats[\"correct\"]\n",
    "    \n",
    "    # Calcula a acurﾃ｡cia (% de acertos)\n",
    "    accuracy = (correct / total * 100) if total > 0 else 0\n",
    "    \n",
    "    # Exibe resultados formatados\n",
    "    print(f\"沒 Modelo: {models[name]}\")\n",
    "    print(f\"   笨 Total exemplos: {total}\")\n",
    "    print(f\"   沁ｯ Acertos: {correct}\")\n",
    "    print(f\"   沒 Acurﾃ｡cia: {accuracy:.2f}%\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
